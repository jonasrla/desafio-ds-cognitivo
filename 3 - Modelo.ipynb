{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confused-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_parquet('data/trusted/training/listing.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "subpref = [i for i in df_listings.columns if 'subprefeitura_' in i]\n",
    "amenities = [i for i in df_listings.columns if 'amenities_' in i]\n",
    "room_type = [i for i in df_listings.columns if 'room_type_' in i]\n",
    "bathroom_description = [i for i in df_listings.columns if 'bathroom_description_' in i]\n",
    "property_type = [i for i in df_listings.columns if 'property_type_' in i]\n",
    "extras = ['number_of_bathrooms',\n",
    "          'bedrooms',\n",
    "          'beds',\n",
    "          'has_availability',\n",
    "          'availability_30',\n",
    "          'availability_60',\n",
    "          'availability_90',\n",
    "          'availability_365',\n",
    "          'number_of_reviews_l30d',\n",
    "          'number_of_reviews_ltm',\n",
    "          'number_of_reviews',\n",
    "          'last_review',\n",
    "          'review_scores_rating',\n",
    "          'review_scores_accuracy',\n",
    "          'review_scores_cleanliness',\n",
    "          'review_scores_checkin',\n",
    "          'review_scores_communication',\n",
    "          'review_scores_location',\n",
    "          'review_scores_value']\n",
    "\n",
    "features = subpref+amenities+room_type+bathroom_description+property_type+extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-beast",
   "metadata": {},
   "source": [
    "preprocessa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "armed-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"number_of_bathrooms\",\n",
    "            \"bedrooms\",\n",
    "            \"beds\",\n",
    "            \"review_scores_rating\",\n",
    "            \"review_scores_accuracy\",\n",
    "            \"review_scores_cleanliness\",\n",
    "            \"review_scores_checkin\",\n",
    "            \"review_scores_communication\",\n",
    "            \"review_scores_location\",\n",
    "            \"review_scores_value\"]:\n",
    "    has_col = f'has_{col}'\n",
    "    df_listings[has_col] = ~df_listings[col].isna()\n",
    "    features.append(has_col)\n",
    "    df_listings[col] = df_listings[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_date = datetime(2021, 3, 21)\n",
    "df_listings['last_review'] = (compiled_date - df_listings['last_review']).apply(lambda d: d.days)\n",
    "df_listings['has_last_review'] = ~df_listings.last_review.isna()\n",
    "df_listings['last_review'] = df_listings['last_review'].fillna(-1)\n",
    "features.append('has_last_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "found-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_datasets(df, id_column, id_list):\n",
    "    return df[df[id_column].isin(id_list)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df_listings.id)\n",
    "\n",
    "validation_size = 1000\n",
    "validation_index = sample(range(len(ids)), validation_size)\n",
    "\n",
    "validation_ids = {listing_id for index, listing_id in enumerate(ids) if index in validation_index}\n",
    "training_ids   = {listing_id for index, listing_id in enumerate(ids) if index not in validation_index}\n",
    "\n",
    "validation_listing  = separa_datasets(df_listings, 'id', validation_ids)\n",
    "training_listing    = separa_datasets(df_listings, 'id', training_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stunning-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(df, features):\n",
    "    df_premium = df[df.subprefeitura.isin(['Sul', 'Barra da Tijuca'])]\n",
    "    df_comum = df[~df.subprefeitura.isin(['Sul', 'Barra da Tijuca'])]\n",
    "    clf_comum = RandomForestClassifier(n_estimators=30).fit(df_comum[features], df_comum['price'])\n",
    "    clf_premium = RandomForestClassifier(n_estimators=30).fit(df_premium[features], df_premium['price'])\n",
    "    return {'comum': clf_comum, 'premium': clf_premium}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "laden-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(df, features, model):\n",
    "    df_premium = df[df.subprefeitura.isin(['Sul', 'Barra da Tijuca'])].copy()\n",
    "    df_comum = df[~df.subprefeitura.isin(['Sul', 'Barra da Tijuca'])].copy()\n",
    "    df_premium['price_predict'] = model['premium'].predict(df_premium[features])\n",
    "    df_comum['price_predict'] = model['comum'].predict(df_comum[features])\n",
    "    return df_comum.append(df_premium, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "detailed-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_custo(df, col, col_pred):\n",
    "    df['diff'] = df[col] - df[col_pred]\n",
    "    quadr_err = ((df['diff'] ** 2).sum() / df.shape[0]) ** (0.5)\n",
    "    magn_err = (df['diff'].abs() > 1000).sum()\n",
    "    quadr_err_no_out = ((df[df['diff'].abs() < 1000]['diff'] ** 2).sum() / (df.shape[0] - magn_err)) ** (0.5)\n",
    "    print('hop!')\n",
    "    return (quadr_err, quadr_err_no_out, magn_err, df[['id', col, col_pred, 'diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welsh-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_naive(df, features):\n",
    "    return RandomForestClassifier(n_estimators=30).fit(df[features], df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bibliographic-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval_naive(df, features, model):\n",
    "    df['price_predict'] = model.predict(df[features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n"
     ]
    }
   ],
   "source": [
    "modelo_separa = [funcao_custo(\n",
    "    model_eval(validation_listing,\n",
    "               features,\n",
    "               model_fit(training_listing,\n",
    "                         features)),\n",
    "    'price',\n",
    "    'price_predict') for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "productive-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n",
      "hop!\n"
     ]
    }
   ],
   "source": [
    "modelo_naive = [funcao_custo(\n",
    "    model_eval_naive(validation_listing,\n",
    "               features,\n",
    "               model_fit_naive(training_listing,\n",
    "                         features)),\n",
    "    'price',\n",
    "    'price_predict') for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "united-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "supreme-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274.5070654980905"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[0] for i in modelo_separa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liked-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2063.8346180421604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[0] for i in modelo_naive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "neither-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264.18958437677395"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[1] for i in modelo_separa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "valued-russian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262.73391298394927"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[1] for i in modelo_naive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "behind-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[2] for i in modelo_separa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "julian-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([i[2] for i in modelo_naive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-senator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
